{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReadyCT Workshop: Hands-On AI\n",
    "\n",
    "Welcome to this hands-on coding workshop! In this notebook, we’ll explore how artificial intelligence (AI) can recognize drawings — just like how people do.\n",
    "\n",
    "We'll be using a real-world dataset from Google called the [Quick, Draw! dataset](https://quickdraw.withgoogle.com/data), which contains millions of doodles collected from people around the world. We'll focus on distinguishing between two types of doodles: cats and dogs.\n",
    "\n",
    "By the end of this notebook, you’ll have trained your own machine learning models to classify images — including a simple neural network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Is AI and How Does It Recognize Images?\n",
    "AI refers to computer programs that can learn from data and make decisions or predictions. One common use of AI is image recognition — for example, teaching a computer to tell the difference between a picture of a cat and a dog.\n",
    "\n",
    "But how can a machine \"see\" a drawing?\n",
    "\n",
    "An image is really just a grid of numbers (pixels).\n",
    "\n",
    "AI learns patterns from these images.\n",
    "\n",
    "Once trained, it can make predictions on new, unseen images.\n",
    "\n",
    "Today, we’ll feed our models simple black-and-white doodles, and they’ll learn to guess: is this a cat or a dog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we start by importing all necessary packages. If you get an error, do `pip install PACKAGE_NAME`, where `PACKAGE_NAME` is the name of the missing package. For `sklearn`, you have to do `pip install scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "\n",
    "import numpy as np\n",
    "import ndjson\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Doodle Dataset\n",
    "\n",
    "We'll start by downloading images of cats and dogs from the Doodle dataset. We have pre-written some code that automatically downloads the data, and prepares it to feed into our machine learning models. If you are interested in 'peeking under the hood', check out the `utils.py` program to see how we downloaded and prepared our data!\n",
    "\n",
    "As a general guide, these are the steps that we do to prepare our dataset:\n",
    "\n",
    "1. Combine the cat and dog images into one single dataset (instead of two different datasets).\n",
    "2. Add a label for each image:\n",
    "   - `0` for **cat**\n",
    "   - `1` for **dog**\n",
    "3. Normalize the images by dividing all pixel values by 255.\n",
    "   - This scales the data to be between `0` and `1`, which helps models learn better.\n",
    "4. Split the data into training and test sets:\n",
    "   - The training set is used to teach the model.\n",
    "   - The test set is used to evaluate how well the model works on new data.\n",
    "   - We split the dataset into 80% training and 20% testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading and visualizing the data - this might take some time!\n",
    "# preparing the data to feed into the models\n",
    "X, y = utils.download_and_preprocess_data(doodles=True)\n",
    "\n",
    "# splitting into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1: Logistic Regression\n",
    "\n",
    "Logistic Regression is a simple yet powerful machine learning model used for classification tasks. It tries to find a decision boundary that separates two classes — in our case, cats and dogs — based on pixel values.\n",
    "\n",
    "This will serve as our baseline model. Later, we’ll compare its performance with more advanced methods.\n",
    "\n",
    "Here's a simple picture to think about how Logistic Regression does its job recognizing cats as cats and dogs as dogs.\n",
    "\n",
    "![logistic regression](figs/logreg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# feeding our training data to the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# feeding our test data to the model and getting the accuracy of the model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "utils.show_10_random_predictions(X_test, y_test, clf, model_type='sklearn', model_name='Logistic Regression', accuracy=acc * 100, dataset_type='doodles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that our Logistic Regression model achieves an accuracy between 60-70%. This means that the model can correctly predict whether the image is a doodle of a cat or a dog 60-70% of the time (exact accuracy is what your model outputs). We will now compare these results against two other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2: Support Vector Machine (SVM)\n",
    "\n",
    "A Support Vector Machine (SVM) is another type of classification model. It works by finding the best boundary that separates two classes of data.\n",
    "\n",
    "Unlike logistic regression, which models probabilities, an SVM tries to maximize the separation between the two classes. This can make it more effective when the classes are not easily separable with a simple line or curve.\n",
    "\n",
    "We'll train the SVM on the same data and compare its performance to the logistic regression model.\n",
    "\n",
    "Again, here's a simple picture to get you thinking about what SVM is going. It also tries to find a boundary between cat and dog data points like Logistic Regression, but also tries to maximize the separation between the boundary, to really confidently say \"yes, this is a cat\", or \"this is really definitely a dog\".\n",
    "\n",
    "![SVM](figs/svm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our SVM model\n",
    "svm_clf = SVC(kernel='linear')  \n",
    "\n",
    "# feeding our training data to the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# feeding our test data to the model and getting the accuracy of the model\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")\n",
    "utils.show_10_random_predictions(X_test, y_test, svm_clf, model_type='sklearn', model_name='SVM', accuracy=svm_acc * 100, dataset_type='doodles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that our SVM model also achieves an accuracy between 60-70%. This means that the model can correctly predict whether the image is a doodle of a cat or a dog 60-70% of the time (exact accuracy is what your model outputs). We will now compare these results against one more model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3: Neural Network (Simple ResNet)\n",
    "\n",
    "Neural networks are *powerful* models that learn by stacking layers of computations. A ResNet, short for Residual Network, is a type of deep neural network that is widely used by ML practitioners as a standard benchmark model. See [this](https://en.wikipedia.org/wiki/Residual_neural_network) if you're interested in learning more about ResNet!\n",
    "\n",
    "In this notebook, we use a very simple version of a ResNet. It includes convolutional layers that detect patterns in the images, and a residual block that helps the model learn more complex features without losing important information.\n",
    "\n",
    "We'll train this network using [PyTorch](https://pytorch.org/), a deep learning library widely used in both research and industry. Then, we'll compare its accuracy to the other models.\n",
    "\n",
    "We start by preparing the data specially for this model, as it requires a different format than what we've used for Logistic Regression and SVM. Again, we have pre-written a program in `utils.py` that takes care of the data pre-processing for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the data to feed to the ResNet\n",
    "train_loader, test_loader = utils.preprocess_pytorch_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to define the model architecture. This is like writing a recipe for a cake, where the cake is our neural network, and we write down what ingredinents go into baking this cake and in what order. We have drawn a simple version of what this model architecture looks like, but don't worry about the details - think of the ResNet as a food processor which takes in your image (which is either a cat or a dog), does some stuff (learns features from the image), and then finally outputs a prediction: either 0 if the model thinks the image is a cat, or 1 if the model think the image is a dog.\n",
    "\n",
    "![simple ResNet](figs/simple_resnet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity  # Residual connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Number of input channels (1 for doodles, 3 for CIFAR)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 16, kernel_size=3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.resblock = ResidualBlock(16)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(16, 2)  # 2 classes (cat/dog)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        x = self.resblock(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the model architecture defined, we will start setting the scene for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# creating our ResNet model from the architecture defined above\n",
    "model = SimpleResNet(in_channels=1).to(device)\n",
    "\n",
    "# defining a \"loss function\" that helps the model learn patterns from the images\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# defining an \"optimizer\" that also helps the model learn patterns\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with everything set in place, we train the ResNet model in a 'training loop'. We feed the data through the neural network 5 times (also called 'epochs') to help it learn complex patterns from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 5  # adjust as needed\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_acc = correct / total\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Accuracy: {epoch_acc * 100:.2f}%\")\n",
    "\n",
    "# Plotting epoch vs accuracy\n",
    "utils.plot_accuracy_curve(train_accuracies, title=\"Epoch vs Training Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained the model, we will feed it the test data, and see how well it can perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# calculating accuracy and displaying model's predictions\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Simple ResNet Test Accuracy: {accuracy:.2f}%\")\n",
    "utils.show_10_random_predictions(X_test, y_test, model, model_type='resnet', model_name='ResNet', accuracy=accuracy, dataset_type='doodles')  # model is your PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Did the ResNet Perform Worse?\n",
    "\n",
    "Even though neural networks like ResNet are more powerful and flexible, they don't always perform better — especially on small or simple datasets like ours.\n",
    "\n",
    "There are a few reasons why the ResNet may have lower accuracy than the logistic regression and SVM models:\n",
    "\n",
    "- The dataset is small (only 1,000 images total), which makes it harder for deep models to learn effectively.\n",
    "- Neural networks have a lot more parameters and need more data to generalize well.\n",
    "- Our ResNet was trained for just a few epochs and kept very simple for this workshop. A more complex version with more layers and training time might perform better.\n",
    "- Simpler models like logistic regression and SVM often work surprisingly well when the input features (pixel patterns) are already quite informative.\n",
    "\n",
    "This is an important lesson in AI: sometimes, **simpler models are better suited to the problem** — especially when data is limited. But for large, complex datasets (like natural photos or videos), deep neural networks usually shine.\n",
    "\n",
    "Note here that the ResNet model achieves around ~50% accuracy. This means it's randomly guessing what the image is - either it will be a cat or a dog. This is like when you flip a coin and you can guess correctly if it's heads or tails 50% of the time.\n",
    "\n",
    "Also note that we only trained our model here for 5 epochs. What happens if we increase that number? We ran that experiment for you, here are the results when we train the model for 10,000 epochs on a powerful GPU.\n",
    "\n",
    "We find that the accuracy starts low, around 55%, but then slowly starts increasing to or near 100%, stabilizing around the 200th epoch. This means the model has learned meaningul features by the 200th epoch, enough to be correctly training the model.\n",
    "\n",
    "![trained for 10000 epochs](figs/01_doodles_acc.png)\n",
    "\n",
    "But what happens when we test our model on the test images? We find that it achieves a higher accuracy than our 5 epoch-trained model, 72%. This shows us that more time training the model on the same small dataset *does* help in increasing the accuracy a little bit.\n",
    "\n",
    "![tested on 50 images](figs/02_doodles_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored how artificial intelligence can be used to recognize hand-drawn doodles. We trained and tested three different models: logistic regression, support vector machine (SVM), and a simple neural network based on the ResNet architecture.\n",
    "\n",
    "Along the way, we learned how to prepare image data, train models, and evaluate their performance. We also saw how even simple models can perform well on visual tasks, and how more advanced models like neural networks can capture more complex patterns.\n",
    "\n",
    "This hands-on activity is just the beginning. The same ideas used here are part of how modern AI systems recognize faces, understand handwriting, power self-driving cars, and more. With practice and curiosity, you can keep exploring and building even more powerful AI models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================\n",
    "================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Content! Classifying Real Images\n",
    "\n",
    "We just classified *doodles* of cats and dogs using three models (Logistic Regression, SVM, ResNet). But what if we now use *real images* of cats and dogs? Isn't that exciting?\n",
    "\n",
    "We'll be using the [CIFAR-10 dataset](https://en.wikipedia.org/wiki/CIFAR-10), which is a famous benchmark dataset of images used in machine learning. There's 10 different classes of images: airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. But we're going to use a small subset of cats and dogs only. \n",
    "\n",
    "We'll do the same thing as before, which is pre-processing the data, and training Logistic Regression, SVM, and ResNet models on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading and visualizing the data - this might take some time!\n",
    "# preparing the data to feed into the models\n",
    "X, X_flat, y = utils.download_and_preprocess_data(doodles=False)\n",
    "\n",
    "# splitting into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHOA!?!? Why do these images look so...blurry? \n",
    "\n",
    "Our laptops often aren't powerful enough (as in, they don't have enough memory and GPU compute power) to handle processing very large datasets. So to keep a light load on your laptops, we are doing 2 things:\n",
    "1. using a smaller subset of cats and dogs data - 250 images per class.\n",
    "2. using a lower resolution.\n",
    "\n",
    "These images are originally 32x32 pixels (and in color!), however for this workshop, we have lowered the resolution to 28x28 pixels. This is what makes these pictures look blurry. Don't worry - let's see what happens! Will our models be able to recognize these cats as cats and dogs as dogs? Only one way to find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1: Logistic Regression\n",
    "\n",
    "Let's run these images through a new Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# feeding our training data to the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# feeding our test data to the model and getting the accuracy of the model\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc * 100:.2f}%\")\n",
    "utils.show_10_random_predictions(X_test, y_test, clf, model_type='sklearn', model_name='Logistic Regression', accuracy=acc * 100, dataset_type='cifar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2: Support Vector Machine (SVM)\n",
    "\n",
    "Again, we'll repeat the experiment for SVM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating our SVM model\n",
    "svm_clf = SVC(kernel='linear')  \n",
    "\n",
    "# feeding our training data to the model\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# feeding our test data to the model and getting the accuracy of the model\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "svm_acc = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Accuracy: {svm_acc * 100:.2f}%\")\n",
    "utils.show_10_random_predictions(X_test, y_test, svm_clf, model_type='sklearn', model_name='SVM', accuracy=svm_acc * 100, dataset_type='cifar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #3: Neural Network (Simple ResNet)\n",
    "\n",
    "Finally, we'll train our deep neural network, Simple ResNet. Note that we have to pre-process the data to get it into a format the neural network can work with, but we've taken care of that for you, so you just need to run the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "train_loader, test_loader = utils.preprocess_pytorch_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to define the architecture of the ResNet again, since it has already been defined earlier and we're not making any changes to the model architecture. We will need to re-instantiate the model, loss function, and optimizer, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# creating our ResNet model from the architecture defined above\n",
    "model = SimpleResNet(in_channels=3).to(device)\n",
    "\n",
    "# defining a \"loss function\" that helps the model learn patterns from the images\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# defining an \"optimizer\" that also helps the model learn patterns\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we now start to train the model with the cats and dogs images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "epochs = 5  # adjust as needed\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_acc = correct / total\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Accuracy: {epoch_acc * 100:.2f}%\")\n",
    "\n",
    "# Plotting epoch vs accuracy\n",
    "utils.plot_accuracy_curve(train_accuracies, title=\"Epoch vs Training Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And final touches...*test* the model to see how well it learned to recognize cat and dog pictures!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# calculating accuracy and displaying model's predictions\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Simple ResNet Test Accuracy: {accuracy:.2f}%\")\n",
    "utils.show_10_random_predictions(X_test, y_test, model, model_type='resnet', model_name='ResNet', accuracy=accuracy, dataset_type='cifar')  # model is your PyTorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![trained for 10000 epochs](figs/03_cifar_acc.png)\n",
    "![tested on 50 images](figs/04_cifar_test.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUMP UP RES TO 32\n",
    "\\\n",
    "\n",
    "\n",
    "kmeans, decision tree, random forest, etc ==> EXPLAIANBLE!!!!!!\n",
    "vits?\n",
    "\n",
    "add resources for them to learn more eg colab, skit learn docs, wikipedia, how to use with python\n",
    "enable them to learn things by theseleves \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise for you:** check the accuracies for each of the models you just ran (Logistic Regression, SVM, ResNet) on this CIFAR-10 cats and dogs dataset, with the same models you ran for the Doodles dataset. \n",
    "\n",
    "- Which model, out of the 6, performed the best?\n",
    "- Did the models trained on the different datasets perform comparably?\n",
    "- What do you think of the difference in performances between the models and datasets? \n",
    "\n",
    "Remember the difference between both datasets - the Doodles dataset is a very simple black-and-white dataset of doodles, wheareas the CIFAR-10 dataset is a color dataset of pictures of real cats and dogs, which contains more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources to learn more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
